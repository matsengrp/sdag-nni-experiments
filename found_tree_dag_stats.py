import click
import pandas as pd
import tempfile
from nni_search import load_dag, load_pps, build_tree_dicts


@click.command()
@click.argument("fasta_path", type=str)
@click.argument("posterior_newick_path", type=str)
@click.argument("posterior_probability_path", type=str)
@click.argument("search_results_path", type=str)
@click.argument("out_path", type=str)
@click.option("--restrict_to_credible_set", type=bool, default=True)
def found_tree_dag_stats(
    fasta_path,
    posterior_newick_path,
    posterior_probability_path,
    search_results_path,
    out_path,
    restrict_to_credible_set=True,
):
    """
    Compute additional sdag stats from a completed nni-search. The stats are the number
    of topologies, sdag nodes, and sdag edges per iteration for the sdag spanned by the
    found toologies that are in the credible set (or postrerior set, depending on the
    parameter restrict_to_credible_set).

    Parameters:
        fasta_path (str): File path for the fasta file.
        posterior_newick_path (str): File path for the newick trees (topologies with
            fake branch lengths) of a Mr. Bayes posterior.
        posterior_probability_path (str): File path for posterior probabilities of the
            topologies in posterior_newick_path.
        search_results_path (str): File path for the results csv generated by the nni-search.
        out_path (str): The file path to write out the sdag stats.
        restrict_to_credible_set (bool): When True, the stats are for the sdag spanned
            by the credible set trees found in an iteration of the nni-search. When
            False, all posterior trees are used instead of just the credible trees.
    """
    results_df = pd.read_csv(search_results_path)
    results_df.drop_duplicates(subset="iter", keep="first", inplace=True)
    to_list = lambda s: list(map(int, s[1:-1].split(","))) if len(s) >= 3 else []
    found_tree_id_lists = results_df.posterior_tree_ids.apply(to_list)

    with open(posterior_newick_path) as posterior_newick_file:
        tree_newicks = posterior_newick_file.readlines()
    if restrict_to_credible_set:
        probabilities = load_pps(posterior_probability_path)
        _, _, tree_cred_map, _ = build_tree_dicts(tree_newicks, probabilities)
        found_cred_tree_id_lists = [
            [tree_id for tree_id in tree_id_list if tree_cred_map[tree_id]]
            for tree_id_list in found_tree_id_lists
        ]
        found_tree_id_lists = found_cred_tree_id_lists
    sdag_stats_header = "iter,tree_count,node_count,edge_count\n"
    sdag_stats = []

    with tempfile.TemporaryDirectory() as temp_dir:
        newick_path = f"{temp_dir}/found_trees.nwk"
        for iter, tree_ids in enumerate(found_tree_id_lists):
            print(f"iter: {iter}")
            if len(tree_ids) > 0:
                with open(newick_path, "a") as temp_newick:
                    for tree_id in tree_ids:
                        temp_newick.write(tree_newicks[tree_id] + "\n")
                _, sdag = load_dag(fasta_path, newick_path, temp_dir)
                tree_count = int(sdag.topology_count())
                node_count = sdag.node_count()
                edge_count = sdag.edge_count()
                sdag_stats.append((iter, tree_count, node_count, edge_count))
            else:
                previous_entry = sdag_stats[-1][1:]
                sdag_stats.append((iter, *previous_entry))
    with open(out_path, "w") as write_out_file:
        write_out_file.write(sdag_stats_header)
        for iter, tree_count, node_count, edge_count in sdag_stats:
            write_out_file.write(f"{iter},{tree_count},{node_count},{edge_count}\n")
    return None


if __name__ == "__main__":
    found_tree_dag_stats()
